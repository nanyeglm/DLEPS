{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计`GSE92742_Broad_LINCS_sig_info.txt`中的元数据信息\n",
    "| 列名              | 含义                                         | 示例                                      |\n",
    "|------------------|--------------------------------------------|-----------------------------------------|\n",
    "| sig_id           | 基因表达调控的唯一标识符，包含实验编号、细胞系、处理时间等信息 | AML001_CD34_24H:A05                       |\n",
    "| pert_id          | 抑制剂的唯一标识符，用于标识化合物或处理类型    | DMSO 表示溶剂对照；BRD-A03772856 是具体化合物的ID。 |\n",
    "| pert_iname       | 抑制剂的名称                                 | DMSO（对照）；trichostatin-a（具体药物）  |\n",
    "| pert_type        | 抑制剂的类型                                 | ctl_vehicle（溶剂对照），trt_cp（化合物处理）  |\n",
    "| cell_id          | 实验使用的细胞系                             | CD34: 表示实验细胞系为CD34。             |\n",
    "| pert_dose        | 抑制剂的剂量                                 | 0.1, 单位后续列 pert_dose_unit 指定。      |\n",
    "| pert_dose_unit   | 抑制剂剂量的单位                             | %, μM（微摩尔）                         |\n",
    "| pert_idose       | 抑制剂量的解释性表示                         | 0.1%, 10 µM                             |\n",
    "| pert_time        | 抑制剂处理的处理时间                         | 24h                                      |\n",
    "| pert_time_unit   | 抑制剂处理时间的单位                         | h（小时）                               |\n",
    "| pert_itime       | 抑制剂处理时间的解释性表示                   | 24 h                                    |\n",
    "| distil_id        | 表示单个实验的重复样本，多个实验可能合并     | AML001_CD34_24H_X1_F1B10:J04            |\n",
    "\n",
    "这行数据描述的是一个实验，实验编号为 AML001，使用 **CD34** 细胞系，处理时间为 **24小时**。实验中使用的扰动剂是 **trichostatin-a**，其 **pert_id** 为 BRD-A19037878，剂量为 1.11111 µM，处理持续时间为 **24小时**。该实验包含两个重复样本，分别位于 AML001_CD34_24H_X1_F1B10:F05 和 AML001_CD34_24H_X3_F1B10:F05。 \n",
    "\n",
    "sig_id列名格式：`<实验编号>_<细胞系>_<时间>:<化合物>:<剂量>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"GSE92742_Broad_LINCS_sig_info.txt\"\n",
    "import pandas as pd\n",
    "\n",
    "#加载sig_info文件\n",
    "sig_info_path =\"/mnt/d/Research/PHD/DLEPS/data/GSE92742/GSE92742_Broad_LINCS_sig_info.txt\"\n",
    "sig_info = pd.read_csv(sig_info_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "#查看文件基本信息\n",
    "unique_sig_ids = sig_info['sig_id'].nunique()\n",
    "unique_pert_ids = sig_info['pert_id'].nunique()\n",
    "unique_pert_iname = sig_info['pert_iname'].nunique()\n",
    "\n",
    "\n",
    "# 输出结果\n",
    "# print(sig_info)\n",
    "print(f\"不重复的实验记录数据(sig_id)数量: {unique_sig_ids}\")\n",
    "print(f\"不重复的化合物标识号(pert_id)数量: {unique_pert_ids}\")\n",
    "print(f\"不重复的化合物名称(pert_iname)数量: {unique_pert_iname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计`GSE92742_Broad_LINCS_sig_info_final.txt`匹配SMILES后的数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"GSE92742_Broad_LINCS_sig_info_final.txt\"\n",
    "import pandas as pd\n",
    "\n",
    "#加载sig_info文件\n",
    "final_smiles_path =\"/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_with_smiles.txt\"\n",
    "final_smiles = pd.read_csv(final_smiles_path, sep=\"\\t\", dtype=str)\n",
    "\n",
    "#查看文件基本信息\n",
    "final_unique_sig_ids = final_smiles['sig_id'].nunique()\n",
    "final_unique_pert_ids = final_smiles['pert_id'].nunique()\n",
    "final_unique_pert_iname = final_smiles['pert_iname'].nunique()\n",
    "final_unique_canonical_smiles = final_smiles['canonical_smiles'].nunique()\n",
    "\n",
    "# 输出结果\n",
    "# print(final_smiles)\n",
    "print(f\"不重复的实验记录数据(sig_id)数量: {final_unique_sig_ids}\")\n",
    "print(f\"不重复的化合物标识号(pert_id)数量: {final_unique_pert_ids}\")\n",
    "print(f\"不重复的化合物名称(pert_iname)数量: {final_unique_pert_iname}\")\n",
    "print(f\"不重复的SMILES数量: {final_unique_canonical_smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件\n",
    "file_path = '/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_final.txt'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 计算不重复的 pert_id 的数量\n",
    "unique_pert_ids = df['pert_id'].nunique()\n",
    "\n",
    "# 输出结果\n",
    "print(f\"不重复的 pert_id 数量: {unique_pert_ids}\")\n",
    "\n",
    "# 查找 canonical_smiles 相同但 pert_id 不同的数据\n",
    "duplicated_smiles = df[df.duplicated(subset=['canonical_smiles'], keep=False)]\n",
    "\n",
    "# 按照 canonical_smiles 分组，检查是否有 pert_id 不同的情况\n",
    "result = []\n",
    "for smile, group in duplicated_smiles.groupby('canonical_smiles'):\n",
    "    if group['pert_id'].nunique() > 1:\n",
    "        result.append(group)\n",
    "\n",
    "# 将结果合并并保存为 CSV 文件\n",
    "if result:\n",
    "    result_df = pd.concat(result)\n",
    "    result_df.to_csv('/mnt/d/Research/PHD/DLEPS/results/duplicated_smiles_diff_pertid.csv', index=False)\n",
    "    print(\"数据已保存到文件: duplicated_smiles_diff_pertid.csv\")\n",
    "else:\n",
    "    print(\"没有找到具有相同 canonical_smiles 但不同 pert_id 的数据。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU加速测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 13:58:23.829936: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-12-12 13:58:23.836419: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3187200000 Hz\n",
      "2024-12-12 13:58:23.840163: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5569a2960a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 13:58:23.840190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-12-12 13:58:23.841715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU设备可用！\n",
      "GPU设备：/physical_device:GPU:0\n",
      "开始在GPU上进行计算...\n",
      "计算完成！\n",
      "矩阵乘法计算耗时：0.00019502639770507812秒\n",
      "如果要查看详细GPU使用情况，请在命令行中运行 `nvidia-smi`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 13:58:24.168189: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.168282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5569a2856d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 13:58:24.168295: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-12-12 13:58:24.170136: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.170166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 4090 major: 8 minor: 9 memoryClockRate(GHz): 2.52\n",
      "pciBusID: 0000:01:00.0\n",
      "2024-12-12 13:58:24.170276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-12-12 13:58:24.170855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-12-12 13:58:24.171528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-12-12 13:58:24.172166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-12-12 13:58:24.173002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-12-12 13:58:24.173693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-12-12 13:58:24.175680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-12-12 13:58:24.175760: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.175788: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.175801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2024-12-12 13:58:24.175825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-12-12 13:58:24.175932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-12-12 13:58:24.175945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2024-12-12 13:58:24.175948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2024-12-12 13:58:24.176084: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.176104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1387] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-12 13:58:24.176127: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.176168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 21844 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9)\n",
      "2024-12-12 13:58:24.176704: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.176728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 4090 major: 8 minor: 9 memoryClockRate(GHz): 2.52\n",
      "pciBusID: 0000:01:00.0\n",
      "2024-12-12 13:58:24.176740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-12-12 13:58:24.176745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-12-12 13:58:24.176749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-12-12 13:58:24.176753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-12-12 13:58:24.176756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-12-12 13:58:24.176759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-12-12 13:58:24.176763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-12-12 13:58:24.176776: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.176786: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:969] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 13:58:24.176788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def check_gpu():\n",
    "    # 检查是否有GPU可用\n",
    "    if tf.test.is_gpu_available():\n",
    "        # 获取当前使用的GPU设备\n",
    "        gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if gpu_devices:\n",
    "            print(\"GPU设备可用！\")\n",
    "            for device in gpu_devices:\n",
    "                print(f\"GPU设备：{device.name}\")\n",
    "            run_gpu_computation()  # 进行GPU计算\n",
    "        else:\n",
    "            print(\"TensorFlow未能识别到GPU设备。\")\n",
    "    else:\n",
    "        print(\"当前环境下没有GPU可用。\")\n",
    "\n",
    "def run_gpu_computation():\n",
    "    # 创建一个简单的计算，执行矩阵乘法\n",
    "    with tf.device('/GPU:0'):  # 确保使用第一个GPU\n",
    "        print(\"开始在GPU上进行计算...\")\n",
    "        \n",
    "        # 定义两个大矩阵进行乘法运算\n",
    "        matrix_size = 1024  # 可以根据你的硬件调整大小\n",
    "        A = tf.random.normal([matrix_size, matrix_size])\n",
    "        B = tf.random.normal([matrix_size, matrix_size])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        C = tf.matmul(A, B)  # 矩阵乘法\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"计算完成！\")\n",
    "        print(f\"矩阵乘法计算耗时：{end_time - start_time}秒\")\n",
    "        \n",
    "        # 如果需要查看GPU的详细信息，可以查看GPU利用率（需要nvidia-smi）\n",
    "        # 可以通过外部工具如nvidia-smi来监控GPU使用情况\n",
    "        print(\"如果要查看详细GPU使用情况，请在命令行中运行 `nvidia-smi`\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_gpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dleps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
