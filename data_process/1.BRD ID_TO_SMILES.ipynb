{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据文件\n",
    "file_path = '/mnt/d/Research/PHD/DLEPS/data/compoundinfo_beta.txt'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# 统计总行数\n",
    "total_rows = data.shape[0]\n",
    "\n",
    "# 统计canonical_smiles列中不重复数据的数量\n",
    "unique_smiles = data['canonical_smiles'].nunique()\n",
    "\n",
    "# 统计每组canonical_smiles的条数\n",
    "smiles_counts = data['canonical_smiles'].value_counts()\n",
    "\n",
    "# 输出结果\n",
    "print(f\"总行数: {total_rows}\")\n",
    "print(f\"canonical_smiles列中不重复数据的数量: {unique_smiles}\")\n",
    "print(f\"每组数据的条数:\")\n",
    "print(smiles_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从`LINCS_small_molecules.tsv`中根据`GSE92742_Broad_LINCS_sig_info.txt`里面的BRD标识符匹配化合物SMILES\n",
    "## 步骤一：准备数据\n",
    "\n",
    "1. **加载数据**：\n",
    "\n",
    "   - 从`GSE92742_Broad_LINCS_sig_info.txt`文件加载信号信息数据到`sig_info_df`。\n",
    "   - 从`LINCS_small_molecules.tsv`文件加载小分子数据到`small_molecules_df`。\n",
    "\n",
    "## 步骤二：匹配SMILES\n",
    "\n",
    "1. **合并数据**：\n",
    "   - 使用`pert_id`作为键，将`sig_info_df`和`small_molecules_df`中的数据合并，保留所有`sig_info_df`中的行，以及`small_molecules_df`中匹配的`canonical_smiles`列。\n",
    "2. **保存结果**：\n",
    "   - 将合并后的数据保存到`GSE92742_Broad_LINCS_sig_info_with_smiles.txt`文件中。\n",
    "\n",
    "## 步骤三：筛选包含BRD的行\n",
    "\n",
    "1. **加载数据**：\n",
    "   - 从`GSE92742_Broad_LINCS_sig_info_with_smiles.txt`文件加载已添加SMILES的数据到`filtered_df`。\n",
    "2. **筛选数据**：\n",
    "   - 筛选出`pert_id`中包含\"BRD\"的行。\n",
    "3. **保存结果**：\n",
    "   - 将筛选后的数据保存到`GSE92742_Broad_LINCS_sig_info_filtered.txt`文件中。\n",
    "\n",
    "## 步骤四：筛选有5次以上重复的分子\n",
    "\n",
    "1. **加载数据**：\n",
    "   - 从`GSE92742_Broad_LINCS_sig_info_filtered.txt`文件加载筛选后的数据到`replicated_df`。\n",
    "2. **统计SMILES出现次数**：\n",
    "   - 统计每个`canonical_smiles`的出现次数。\n",
    "   - 筛选出出现次数大于5次的SMILES。\n",
    "3. **筛选数据**：\n",
    "   - 保留SMILES出现次数大于5次的行。\n",
    "4. **保存结果**：\n",
    "   - 将筛选后的数据保存到`GSE92742_Broad_LINCS_sig_info_replicated.txt`文件中。\n",
    "\n",
    "## 步骤五：验证SMILES的有效性\n",
    "\n",
    "1. **加载数据**：\n",
    "   - 从`GSE92742_Broad_LINCS_sig_info_replicated.txt`文件加载数据到`validated_df`。\n",
    "2. **验证SMILES**：\n",
    "   - 使用RDKit库验证每个SMILES是否有效。\n",
    "3. **筛选数据**：\n",
    "   - 保留SMILES有效的行。\n",
    "4. **保存结果**：\n",
    "   - 将验证后的数据保存到`GSE92742_Broad_LINCS_sig_info_final.txt`文件中。\n",
    "\n",
    "## 步骤六：统计基本信息\n",
    "\n",
    "1. **加载数据**：\n",
    "   - 从`GSE92742_Broad_LINCS_sig_info_final.txt`文件加载最终处理后的数据到`sig_info`。\n",
    "2. **统计信息**：\n",
    "   - 输出前五行数据。\n",
    "   - 统计唯一`sig_id`、`pert_id`和`pert_iname`的数量。\n",
    "   - 统计包含\"BRD\"的独一无二的`pert_id`数量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# 文件路径配置\n",
    "sig_info_path = '/mnt/d/Research/PHD/DLEPS/data/GSE92742/GSE92742_Broad_LINCS_sig_info.txt'\n",
    "small_molecules_path = '/mnt/d/Research/PHD/DLEPS/data/GSE92742/LINCS_small_molecules.tsv'\n",
    "output_with_smiles_path = '/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_with_smiles.txt'\n",
    "output_filtered_path = '/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_filtered.txt'\n",
    "output_replicated_path = '/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_replicated.txt'\n",
    "output_final_path = '/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_final.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_statistics(file_path):\n",
    "    \"\"\"统计文件中的基本信息\"\"\"\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)\n",
    "    \n",
    "    # 总数量统计\n",
    "    total_sig_id_count = df['sig_id'].count()\n",
    "    total_pert_id_count = df['pert_id'].count()\n",
    "    total_pert_iname_count = df['pert_iname'].count()\n",
    "    total_canonical_smiles_count = df['canonical_smiles'].count()\n",
    "    \n",
    "    # 不重复数量统计\n",
    "    unique_sig_id_count = df['sig_id'].nunique()\n",
    "    unique_pert_id_count = df['pert_id'].nunique()\n",
    "    unique_pert_iname_count = df['pert_iname'].nunique()\n",
    "    unique_canonical_smiles_count = df['canonical_smiles'].nunique()\n",
    "    \n",
    "    # canonical_smiles为空和不为空的统计\n",
    "    empty_smiles_count = df['canonical_smiles'].isna().sum()\n",
    "    non_empty_smiles_count = df['canonical_smiles'].notna().sum()\n",
    "    \n",
    "    # pert_id 开头是 BRD 的统计\n",
    "    brd_entries = df[df['pert_id'].str.startswith('BRD', na=False)]\n",
    "    total_brd_count = brd_entries.shape[0]\n",
    "    unique_brd_pert_id_count = brd_entries['pert_id'].nunique()\n",
    "    empty_smiles_in_brd_count = brd_entries['canonical_smiles'].isna().sum()\n",
    "    non_empty_smiles_in_brd_count = brd_entries['canonical_smiles'].notna().sum()\n",
    "    \n",
    "    # BRD 开头的条目中重复次数最多的前五个 pert_id\n",
    "    top_brd_pert_ids = (\n",
    "        brd_entries['pert_id']\n",
    "        .value_counts()\n",
    "        .head(5)\n",
    "    )\n",
    "    \n",
    "    # pert_type 列的统计\n",
    "    pert_type_counts = df['pert_type'].value_counts()\n",
    "    total_pert_type_count = len(pert_type_counts)\n",
    "    \n",
    "    # 查找 canonical_smiles 相同但 pert_id 不同的数据\n",
    "    duplicated_smiles = df[df.duplicated(subset=['canonical_smiles'], keep=False)]\n",
    "    result = []\n",
    "    for smile, group in duplicated_smiles.groupby('canonical_smiles'):\n",
    "        if group['pert_id'].nunique() > 1:\n",
    "            result.append(group)\n",
    "    \n",
    "    if result:\n",
    "        result_df = pd.concat(result)\n",
    "        result_file_path = '/mnt/d/Research/PHD/DLEPS/results/duplicated_smiles_diff_pertid.csv'\n",
    "        result_df.to_csv(result_file_path, index=False)\n",
    "        duplicated_smiles_message = f\"数据已保存到文件: {result_file_path}\"\n",
    "    else:\n",
    "        duplicated_smiles_message = \"没有找到具有相同 canonical_smiles 但不同 pert_id 的数据。\"\n",
    "\n",
    "    # 打印统计信息\n",
    "    print(f\"文件: {file_path}\")\n",
    "    print(f\"总数量统计:\")\n",
    "    print(f\"  sig_id 总数: {total_sig_id_count}\")\n",
    "    print(f\"  pert_id 总数: {total_pert_id_count}\")\n",
    "    print(f\"  pert_iname 总数: {total_pert_iname_count}\")\n",
    "    print(f\"  canonical_smiles 总数: {total_canonical_smiles_count}\")\n",
    "    print(f\"不重复数量统计:\")\n",
    "    print(f\"  不重复的 sig_id 数量: {unique_sig_id_count}\")\n",
    "    print(f\"  不重复的 pert_id 数量: {unique_pert_id_count}\")\n",
    "    print(f\"  不重复的 pert_iname 数量: {unique_pert_iname_count}\")\n",
    "    print(f\"  不重复的 canonical_smiles 数量: {unique_canonical_smiles_count}\")\n",
    "    print(f\"附加统计信息:\")\n",
    "    print(f\"  具有空 canonical_smiles 的 pert_id 数量: {empty_smiles_count}\")\n",
    "    print(f\"  具有非空 canonical_smiles 的 pert_id 数量: {non_empty_smiles_count}\")\n",
    "    print(f\"pert_id 开头是 BRD 的统计:\")\n",
    "    print(f\"  BRD 开头的条目总数: {total_brd_count}\")\n",
    "    print(f\"  不重复的 BRD 开头的 pert_id 数量: {unique_brd_pert_id_count}\")\n",
    "    print(f\"  BRD 开头的条目中，canonical_smiles 为空的数量: {empty_smiles_in_brd_count}\")\n",
    "    print(f\"  BRD 开头的条目中，canonical_smiles 不为空的数量: {non_empty_smiles_in_brd_count}\")\n",
    "    print(f\"  BRD 开头的条目中重复次数最多的前五个 pert_id 名称及其重复次数:\")\n",
    "    print(top_brd_pert_ids)\n",
    "    print(f\"pert_type 列的统计:\")\n",
    "    print(f\"  不同种类的数量: {total_pert_type_count}\")\n",
    "    print(f\"  每个种类的数量:\")\n",
    "    print(pert_type_counts)\n",
    "    print(f\"相同 canonical_smiles 但不同 pert_id 的数据检查:\")\n",
    "    print(duplicated_smiles_message)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smiles_column():\n",
    "    \"\"\"Step 1-3: 匹配 SMILES 并添加到数据\"\"\"\n",
    "    sig_info_df = pd.read_csv(sig_info_path, sep='\\t')\n",
    "    small_molecules_df = pd.read_csv(small_molecules_path, sep='\\t')\n",
    "    merged_df = sig_info_df.merge(small_molecules_df[['pert_id', 'canonical_smiles']], on='pert_id', how='left')\n",
    "    merged_df.to_csv(output_with_smiles_path, sep='\\t', index=False)\n",
    "    print(f\"添加canonical_smiles列后的结果已保存到: {output_with_smiles_path}\")\n",
    "    analyze_statistics(output_with_smiles_path)  # 输出文件统计信息\n",
    "\n",
    "add_smiles_column()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_brd_data():\n",
    "    \"\"\"Step 4-5: 筛选出包含 BRD 的行\"\"\"\n",
    "    merged_df = pd.read_csv(output_with_smiles_path, sep='\\t')\n",
    "    filtered_df = merged_df[merged_df['pert_id'].str.contains('BRD', na=False)]\n",
    "    filtered_df.to_csv(output_filtered_path, sep='\\t', index=False)\n",
    "    print(f\"过滤后的结果（仅保留pert_id包含BRD）已保存到: {output_filtered_path}\")\n",
    "    analyze_statistics(output_filtered_path)  # 输出文件统计信息\n",
    "\n",
    "filter_brd_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_replicates():\n",
    "    \"\"\"Step 6: 保留有5次以上重复的分子\"\"\"\n",
    "    filtered_df = pd.read_csv(output_filtered_path, sep='\\t')\n",
    "    \n",
    "    # 统计每个 SMILES 的出现次数\n",
    "    smiles_counts = filtered_df['canonical_smiles'].value_counts()\n",
    "    replicated_smiles = smiles_counts[smiles_counts > 5].index\n",
    "    replicated_df = filtered_df[filtered_df['canonical_smiles'].isin(replicated_smiles)]\n",
    "    \n",
    "    replicated_df.to_csv(output_replicated_path, sep='\\t', index=False)\n",
    "    print(f\"筛选后（SMILES 出现次数大于 5）的数据已保存到: {output_replicated_path}\")\n",
    "    analyze_statistics(output_replicated_path)  # 输出文件统计信息\n",
    "\n",
    "filter_replicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_smiles():\n",
    "    \"\"\"Step 7-8: 验证 SMILES 是否有效\"\"\"\n",
    "    replicated_df = pd.read_csv(output_replicated_path, sep='\\t')\n",
    "    \n",
    "    # 验证 SMILES 是否能被 RDKit 解析\n",
    "    def is_valid_smiles(smiles):\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            return mol is not None\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    validated_df = replicated_df[replicated_df['canonical_smiles'].apply(is_valid_smiles)]\n",
    "    validated_df.to_csv(output_final_path, sep='\\t', index=False)\n",
    "    print(f\"最终处理后的数据已保存到: {output_final_path}\")\n",
    "    analyze_statistics(output_final_path)  # 输出文件统计信息\n",
    "\n",
    "validate_smiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress import parse, write_gct\n",
    "\n",
    "gctx_file = \"/mnt/d/Research/PHD/DLEPS/References/LINCS L1000 Chemical Perturbations (2021).gctx\"  # 替换为实际路径\n",
    "data = parse.parse(gctx_file)\n",
    "\n",
    "# 查看数据\n",
    "print(data.data_df.head())\n",
    "\n",
    "expression_data = data.data_df\n",
    "\n",
    "# 示例：查看前几行\n",
    "print(expression_data.head())\n",
    "\n",
    "row_metadata = data.row_metadata_df\n",
    "print(row_metadata.head())\n",
    "\n",
    "\n",
    "col_metadata = data.col_metadata_df\n",
    "print(col_metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_line_breaks(file_path, expected_columns):\n",
    "    \"\"\"检查文件中换行有问题的行\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    problematic_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        columns = line.split('\\t')\n",
    "        if len(columns) != expected_columns:\n",
    "            problematic_lines.append((i + 1, line))\n",
    "    \n",
    "    if problematic_lines:\n",
    "        print(f\"在文件 {file_path} 中发现换行有问题的行:\")\n",
    "        for line_num, content in problematic_lines:\n",
    "            print(f\"行号 {line_num}: {content}\")\n",
    "    else:\n",
    "        print(f\"文件 {file_path} 中没有发现换行有问题的行。\")\n",
    "\n",
    "# 假设文件中应该有 14 列（根据提供的示例数据格式）\n",
    "expected_columns = 13\n",
    "check_line_breaks('/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_with_smiles.txt', expected_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLEPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
