{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `canonical_smiles` 对应的`sig_id`数据，然后计算这些基因表达的平均值。\n",
    "这段代码的主要功能是从 `sig_info` 文件中读取数据，按 `canonical_smiles` 分组，然后并行处理每个 `canonical_smiles` 对应的 `sig_id` 数据，计算基因表达的平均值，并最终将结果保存为 CSV 文件。\n",
    "\n",
    "1. **读取 `sig_info` 文件**：`read_sig_info` 函数读取 `sig_info` 文件并返回一个 DataFrame。\n",
    "2. **按 `canonical_smiles` 分组**：`group_by_smiles` 函数按 `canonical_smiles` 分组，返回每个 `canonical_smiles` 对应的所有 `sig_id`。\n",
    "3. **并行处理**：`extract_and_compute_averages_parallel` 函数使用多进程并行处理每个 `canonical_smiles` 的数据提取和计算任务。\n",
    "4. **保存结果**：`save_combined_data` 函数将综合的 DataFrame 转置并保存为 CSV 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import sys\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "\n",
    "def read_sig_info(sig_info_path):\n",
    "    \"\"\"\n",
    "    读取 sig_info 文件，并添加 canonical_smiles 列。\n",
    "    \"\"\"\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 开始读取 sig_info 文件: {sig_info_path}\")\n",
    "    try:\n",
    "        sig_info = pd.read_csv(sig_info_path, sep=\"\\t\")\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 成功读取 sig_info 文件，共包含 {len(sig_info)} 条记录。\")\n",
    "        return sig_info\n",
    "    except Exception as e:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 读取 sig_info 文件时出错: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "def group_by_smiles(sig_info_df):\n",
    "    \"\"\"\n",
    "    按照 canonical_smiles 分组，获取每个 canonical_smiles 对应的所有 sig_id。\n",
    "    \"\"\"\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 开始按 'canonical_smiles' 分组.\")\n",
    "    if 'canonical_smiles' not in sig_info_df.columns:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 错误: sig_info 文件缺少 'canonical_smiles' 列。\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    grouped = sig_info_df.groupby('canonical_smiles')['sig_id'].apply(list).to_dict()\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 共分组 {len(grouped)} 个不同的 'canonical_smiles'。\")\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def process_smiles(smiles, sig_ids, gctx_path):\n",
    "    \"\"\"\n",
    "    处理单个 canonical_smiles 的数据提取和计算任务。\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # 提取对应的 sig_id 数据\n",
    "        gctx_data = parse(gctx_path, cid=sig_ids)\n",
    "        data_df = gctx_data.data_df  # 行：基因，列：sig_id\n",
    "\n",
    "        # 计算每行（基因）的平均值\n",
    "        gene_means = data_df.mean(axis=1)\n",
    "        gene_means.name = smiles  # 设置 Series 名称为 canonical_smiles\n",
    "\n",
    "        # 打印一些统计信息\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\n",
    "            f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 完成 'canonical_smiles' {smiles} 的处理。\"\n",
    "            f\" 数据维度: {data_df.shape}，耗时: {elapsed:.2f} 秒。\"\n",
    "        )\n",
    "        return gene_means\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 错误: 处理 'canonical_smiles' {smiles} 时出错: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_and_compute_averages_parallel(gctx_path, grouped_data, max_workers=4):\n",
    "    \"\"\"\n",
    "    使用并行处理提取和计算平均值，并一次性合并所有结果。\n",
    "    集成 tqdm 进度条以显示处理进度。\n",
    "    \"\"\"\n",
    "    combined_df = None\n",
    "    total_smiles = len(grouped_data)\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 开始并行提取表达数据并计算平均值，共 {total_smiles} 个 'canonical_smiles'。\")\n",
    "\n",
    "    gene_means_list = []  # 用于收集所有 gene_means\n",
    "    smiles_list = []      # 用于收集对应的 canonical_smiles\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_smiles, smiles, sig_ids, gctx_path): smiles\n",
    "            for smiles, sig_ids in grouped_data.items()\n",
    "        }\n",
    "\n",
    "        # 使用 tqdm 包装 as_completed 生成器\n",
    "        for future in tqdm(as_completed(futures), total=total_smiles, desc=\"Processing smiles\"):\n",
    "            smiles = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    gene_means_list.append(result)\n",
    "                    smiles_list.append(smiles)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 错误: 并行任务处理 'canonical_smiles' {smiles} 时出错: {e}\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "\n",
    "    if gene_means_list:\n",
    "        # 将所有 gene_means 合并为一个 DataFrame\n",
    "        combined_df = pd.concat(gene_means_list, axis=1)\n",
    "        combined_df.columns = smiles_list  # 替换列名为 canonical_smiles\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 并行处理完成。\")\n",
    "        print(f\"    综合 DataFrame 的维度: {combined_df.shape}\")\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 没有有效的 gene_means 结果。\", file=sys.stderr)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def save_combined_data(combined_df, output_path):\n",
    "    \"\"\"\n",
    "    将综合 DataFrame 保存为 CSV 文件，并转置。\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] 开始保存综合数据到 CSV 文件: {output_path}\")\n",
    "    try:\n",
    "        # 转置 DataFrame，使 canonical_smiles 成为行，基因 ID 成为列\n",
    "        combined_df = combined_df.T\n",
    "        # 重置索引，将 canonical_smiles 作为一列\n",
    "        combined_df.reset_index(inplace=True)\n",
    "        # 重命名列名\n",
    "        combined_df.rename(columns={'index': 'smiles'}, inplace=True)\n",
    "        # 保存为 CSV 文件，不保存索引\n",
    "        combined_df.to_csv(output_path, index=False)\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 综合数据已成功保存至: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 保存综合数据时出错: {e}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 设置文件路径\n",
    "    sig_info_path = \"/mnt/d/Research/PHD/DLEPS/results/GSE92742_Broad_LINCS_sig_info_final.txt\" # 上一个1.BRD ID_TO_SMILES.ipynb代码输出的文件\n",
    "    gctx_path = \"/mnt/d/Research/PHD/DLEPS/data/GSE92742/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx\"\n",
    "    output_combined_path = \"/mnt/d/Research/PHD/DLEPS/results/combined_smiles_averages.csv\"\n",
    "\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 脚本开始运行.\")\n",
    "    print(f\"    sig_info 文件路径: {sig_info_path}\")\n",
    "    print(f\"    .gctx 文件路径: {gctx_path}\")\n",
    "    print(f\"    输出文件路径: {output_combined_path}\")\n",
    "\n",
    "    # 1. 读取 sig_info 文件\n",
    "    sig_info_df = read_sig_info(sig_info_path)\n",
    "    if sig_info_df is None:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 无法读取 sig_info 文件，脚本终止。\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # 2. 按 canonical_smiles 分组\n",
    "    grouped_data = group_by_smiles(sig_info_df)\n",
    "    if grouped_data is None:\n",
    "        return\n",
    "\n",
    "    # 3. 使用并行提取表达数据并计算平均值\n",
    "    combined_df = extract_and_compute_averages_parallel(gctx_path, grouped_data, max_workers=32)  # 根据CPU核数调整 max_workers\n",
    "\n",
    "    if combined_df is not None and not combined_df.empty:\n",
    "        # 4. 保存综合数据\n",
    "        save_combined_data(combined_df, output_combined_path)\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 没有数据可保存。\", file=sys.stderr)\n",
    "\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 脚本运行结束.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出文件数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件，尝试不同的分隔符\n",
    "file_path = '/mnt/d/Research/PHD/DLEPS/results/combined_smiles_averages.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep=',')\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时出错: {e}\")\n",
    "    df = pd.read_csv(file_path)  # 尝试默认分隔符\n",
    "\n",
    "# 打印列名\n",
    "print(\"列名:\", df.columns.tolist())\n",
    "\n",
    "# # 查看前几行\n",
    "# print(df.head())\n",
    "# # 查看后几行\n",
    "# print(df.tail())\n",
    "\n",
    "# 检查'smiles'列是否存在\n",
    "if 'smiles' in df.columns:\n",
    "    unique_smiles = df['smiles'].nunique()\n",
    "    print(f'Unique SMILES: {unique_smiles}')\n",
    "else:\n",
    "    print(\"错误: 'smiles' 列不存在于DataFrame中。请检查列名是否正确。\")\n",
    "\n",
    "# 检查数据结构\n",
    "if df is not None:\n",
    "    # 获取行数和列数\n",
    "    num_rows, num_cols = df.shape\n",
    "    print(f\"数据集包含 {num_rows} 行和 {num_cols} 列。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只保留landmark基因的列数据\n",
    "1. 从文件 `/mnt/d/Research/PHD/DLEPS/results/combined_smiles_averages.csv` 中加载数据。\n",
    "\n",
    "2. 从文件 `/mnt/d/Research/PHD/DLEPS/data/GSE92742/GSE92742_Broad_LINCS_gene_info_delta_landmark.txt` 中提取 `landmark` 基因的 ID。\n",
    "\n",
    "3. 只保留 `landmark` 基因对应的列，输出结果到`/mnt/d/Research/PHD/DLEPS/results/filtered_landmark_smiles.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "combined_smiles_path = '/mnt/d/Research/PHD/DLEPS/results/combined_smiles_averages.csv'\n",
    "landmark_genes_path = '/mnt/d/Research/PHD/DLEPS/data/GSE92742/GSE92742_Broad_LINCS_gene_info.txt'\n",
    "\n",
    "# 1. 读取 combined_smiles_averages.csv 文件\n",
    "try:\n",
    "    combined_df = pd.read_csv(combined_smiles_path, sep=',')\n",
    "    print(f\"成功读取文件: {combined_smiles_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时出错: {e}\")\n",
    "    combined_df = None\n",
    "\n",
    "if combined_df is not None:\n",
    "    # 查看前几行以确认加载成功\n",
    "    print(\"combined_smiles_averages.csv 文件前几行:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # 2. 读取 landmark 基因列表\n",
    "    try:\n",
    "        landmark_df = pd.read_csv(landmark_genes_path, sep='\\t')\n",
    "        print(f\"成功读取文件: {landmark_genes_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取 landmark 基因文件时出错: {e}\")\n",
    "        landmark_df = None\n",
    "\n",
    "    if landmark_df is not None:\n",
    "        # 筛选 pr_is_lm=1 的基因\n",
    "        landmark_genes = landmark_df[landmark_df['pr_is_lm'] == 1]['pr_gene_id'].astype(str).tolist()\n",
    "        print(f\"landmark 基因数量 (pr_is_lm=1): {len(landmark_genes)}\")\n",
    "\n",
    "        # 检查 landmark 基因列是否在 combined_smiles_averages.csv 中\n",
    "        available_genes = [gene for gene in landmark_genes if gene in combined_df.columns]\n",
    "        print(f\"在数据中找到的 landmark 基因数量: {len(available_genes)}\")\n",
    "\n",
    "        # 找到未匹配的基因\n",
    "        missing_genes = [gene for gene in landmark_genes if gene not in combined_df.columns]\n",
    "\n",
    "        # 打印未找到的基因\n",
    "        if missing_genes:\n",
    "            print(f\"未找到的 landmark 基因数量: {len(missing_genes)}\")\n",
    "            print(\"未找到的基因列表:\")\n",
    "            print(missing_genes)\n",
    "        else:\n",
    "            print(\"所有 landmark 基因都在数据中找到了！\")\n",
    "\n",
    "        # 只保留 'smiles' 列和 landmark 基因对应的列\n",
    "        columns_to_keep = ['smiles'] + available_genes\n",
    "        filtered_df = combined_df[columns_to_keep]\n",
    "\n",
    "        # 输出结果\n",
    "        print(\"过滤后的 DataFrame:\")\n",
    "        print(filtered_df.head())\n",
    "\n",
    "        # 保存过滤后的 DataFrame\n",
    "        output_filtered_path = '/mnt/d/Research/PHD/DLEPS/results/L1000_landmark.csv'\n",
    "        filtered_df.to_csv(output_filtered_path, index=False)\n",
    "        print(f\"过滤后的数据已保存至: {output_filtered_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "filtered_landmark_path = '/mnt/d/Research/PHD/DLEPS/results/L1000_landmark.csv'\n",
    "\n",
    "# 读取数据\n",
    "try:\n",
    "    filtered_df = pd.read_csv(filtered_landmark_path)\n",
    "    print(f\"成功读取文件: {filtered_landmark_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时出错: {e}\")\n",
    "    filtered_df = None\n",
    "\n",
    "# 检查数据结构\n",
    "if filtered_df is not None:\n",
    "    # 获取行数和列数\n",
    "    num_rows, num_cols = filtered_df.shape\n",
    "    print(f\"数据集包含 {num_rows} 行和 {num_cols} 列。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将 `/mnt/d/Research/PHD/DLEPS/results/filtered_landmark_smiles.csv` 文件的 smiles 列划分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 文件路径\n",
    "filtered_landmark_path = '/mnt/d/Research/PHD/DLEPS/results/L1000_landmark.csv'\n",
    "train_output_path = '/mnt/d/Research/PHD/DLEPS/results/train_SMILES_demo.csv'\n",
    "test_output_path = '/mnt/d/Research/PHD/DLEPS/results/test_SMILES_demo.csv'\n",
    "\n",
    "# 读取数据\n",
    "try:\n",
    "    filtered_df = pd.read_csv(filtered_landmark_path)\n",
    "    print(f\"成功读取文件: {filtered_landmark_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时出错: {e}\")\n",
    "    filtered_df = None\n",
    "\n",
    "# 提取 SMILES 列并划分数据集\n",
    "if filtered_df is not None:\n",
    "    if 'smiles' in filtered_df.columns:\n",
    "        # 提取 smiles 列\n",
    "        smiles = filtered_df['smiles']\n",
    "        print(f\"成功提取 'smiles' 列，包含 {len(smiles)} 条记录。\")\n",
    "\n",
    "        # 划分训练集和测试集\n",
    "        train_smiles, test_smiles = train_test_split(smiles, test_size=0.2, random_state=42)\n",
    "        print(f\"划分完成：训练集 {len(train_smiles)} 条，测试集 {len(test_smiles)} 条。\")\n",
    "\n",
    "        # 保存训练集和测试集\n",
    "        try:\n",
    "            train_smiles.to_csv(train_output_path, index=False, header=['smiles'])\n",
    "            test_smiles.to_csv(test_output_path, index=False, header=['smiles'])\n",
    "            print(f\"训练集已保存至: {train_output_path}\")\n",
    "            print(f\"测试集已保存至: {test_output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存文件时出错: {e}\")\n",
    "    else:\n",
    "        print(\"错误: 数据集中不存在 'smiles' 列。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLEPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
