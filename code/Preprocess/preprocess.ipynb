{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for the SMILES processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/d/Research/PHD/DLEPS/code/DLEPS')\n",
    "import molecule_vae\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = pd.read_csv('/mnt/d/Research/PHD/DLEPS/results/train_SMILES_demo.csv')\n",
    "dt2 = pd.read_csv('/mnt/d/Research/PHD/DLEPS/results/test_SMILES_demo.csv')\n",
    "\n",
    "smiles = np.concatenate([dt1['smiles'].values, dt2['smiles'].values],axis=0) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smiles[2])\n",
    "MolToSmiles(MolFromSmiles(smiles[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#smiles = smiles[:100]\n",
    "smiles_rdkit = []\n",
    "iid = []\n",
    "for i in range(len(smiles)):\n",
    "    try:\n",
    "        smiles_rdkit.append(MolToSmiles(MolFromSmiles(smiles[ i ])))\n",
    "        iid.append(i)\n",
    "        #print(i)\n",
    "    except:\n",
    "        print(\"Error at %d\" % (i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8889\n",
      "8889\n"
     ]
    }
   ],
   "source": [
    "print(len(smiles))\n",
    "print(len(iid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smiles_rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zinc_tokenizer(cfg):\n",
    "    long_tokens = [a for a in list(cfg._lexical_index.keys()) if xlength(a) > 1] ####\n",
    "    replacements = ['$','%','^'] # ,'&']\n",
    "    assert xlength(long_tokens) == len(replacements) ####xzw\n",
    "    for token in replacements: \n",
    "        assert token not in cfg._lexical_index ####\n",
    "    \n",
    "    def tokenize(smiles):\n",
    "        for i, token in enumerate(long_tokens):\n",
    "            smiles = smiles.replace(token, replacements[i])\n",
    "        tokens = []\n",
    "        for token in smiles:\n",
    "            try:\n",
    "                ix = replacements.index(token)\n",
    "                tokens.append(long_tokens[ix])\n",
    "            except:\n",
    "                tokens.append(token)\n",
    "        return tokens\n",
    "    \n",
    "    return tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def xlength(y):\n",
    "    return reduce(lambda sum, element: sum + 1, y, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zinc_grammar\n",
    "import nltk\n",
    "\n",
    "_tokenize = get_zinc_tokenizer(zinc_grammar.GCFG)\n",
    "_parser = nltk.ChartParser(zinc_grammar.GCFG)\n",
    "_productions = zinc_grammar.GCFG.productions()\n",
    "_prod_map = {}\n",
    "for ix, prod in enumerate(_productions):\n",
    "    _prod_map[prod] = ix\n",
    "MAX_LEN = 277\n",
    "_n_chars = len(_productions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_rd = smiles_rdkit[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "        \"\"\" Encode a list of smiles strings into the latent space \"\"\"\n",
    "        assert type(smiles_rdkit) == list\n",
    "        tokens = map(_tokenize, smiles_rdkit)\n",
    "        parse_trees = []\n",
    "        i = 0\n",
    "        badi = []\n",
    "        for t in tokens:\n",
    "            #while True:\n",
    "            try:\n",
    "                tp = next(_parser.parse(t))\n",
    "                parse_trees.append(tp)\n",
    "            except:\n",
    "                print(\"Parse tree error at %d\" % i)\n",
    "                badi.append(i)\n",
    "            i += 1\n",
    "            #print(i)\n",
    "        productions_seq = [tree.productions() for tree in parse_trees]\n",
    "        indices = [np.array([_prod_map[prod] for prod in entry], dtype=int) for entry in productions_seq]\n",
    "        one_hot = np.zeros((len(indices), MAX_LEN, _n_chars), dtype=np.float32)\n",
    "        for i in range(len(indices)):\n",
    "            num_productions = len(indices[i])\n",
    "            if num_productions > MAX_LEN:\n",
    "                print(\"Too large molecules, out of range\")\n",
    "            #print(\"i=  {%d} len(indices)=  {%d} num_productions = %d \" % (i,len(indices),num_productions))\n",
    "                one_hot[i][np.arange(MAX_LEN),indices[i][:MAX_LEN]] = 1.\n",
    "            else:    \n",
    "                one_hot[i][np.arange(num_productions),indices[i]] = 1.\n",
    "                one_hot[i][np.arange(num_productions, MAX_LEN),-1] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iix = np.arange(len(smiles_rdkit))\n",
    "iidx = [i for i in iix if i not in badi]\n",
    "len(iidx)\n",
    "iid2 = np.array(iid)[iidx]\n",
    "len(iid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L962 = np.genfromtxt('/mnt/d/Research/PHD/DLEPS/results/L1000_landmark.csv', delimiter=',')\n",
    "L962 = L962[iid2]\n",
    "print(L962.shape)\n",
    "num_examples = L962.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.arange(num_examples)\n",
    "np.random.shuffle(perm)\n",
    "#L962 = L962[perm]\n",
    "smile_rd = one_hot[perm]\n",
    "TEST_SIZE = 3000\n",
    "#L962_train = L962[TEST_SIZE:]\n",
    "smile_train = smile_rd[TEST_SIZE:]\n",
    "#L962_test = L962[:TEST_SIZE]\n",
    "smile_test = smile_rd[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)[source]\n",
    "np.savetxt(\"/mnt/d/Research/PHD/DLEPS/results/L1000_train.csv\",L962_train, delimiter = ',')\n",
    "np.savetxt(\"/mnt/d/Research/PHD/DLEPS/results/L1000_test.csv\",L962_test, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('SMILE_train_demo.h5', 'w')\n",
    "h5f.create_dataset('data', data=smile_train)\n",
    "h5f.close()\n",
    "\n",
    "h5f = h5py.File('SMILE_test_demo.h5', 'w')\n",
    "h5f.create_dataset('data', data=smile_test)\n",
    "h5f.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dleps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
